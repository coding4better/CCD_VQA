"""
ä½¿ç”¨ç¤ºä¾‹ï¼šå¦‚ä½•é›†æˆå’Œè¿è¡Œä¸€è‡´æ€§æ£€æŸ¥å®éªŒ

æ­¤æ–‡ä»¶å±•ç¤ºäº†åœ¨å®é™…é¡¹ç›®ä¸­å¦‚ä½•ä½¿ç”¨ exp2_consistency_check æ¨¡å—ã€‚
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

import json
import numpy as np
from datetime import datetime


def example_1_basic_usage():
    """ç¤ºä¾‹ 1: åŸºç¡€ä½¿ç”¨ - ç›´æ¥å¯¼å…¥å’Œä½¿ç”¨å‡½æ•°"""
    print("\n" + "="*80)
    print("ç¤ºä¾‹ 1: åŸºç¡€ä½¿ç”¨")
    print("="*80)
    
    from description_check.exp2_consistency_check import (
        load_baseline_descriptions,
        load_qa_data,
        extract_qa_sentences,
        check_consistency
    )
    
    # åŠ è½½æ•°æ®
    baseline_desc = load_baseline_descriptions(
        "/home/24068286g/CCD_VQA/VRU/src/description_generation/gemini_descriptions_20260119_062930.json"
    )
    qa_data = load_qa_data(
        "/home/24068286g/CCD_VQA/VRU/src/description_generation/generated_vqa_eng.json"
    )
    
    print(f"âœ“ åŠ è½½äº† {len(baseline_desc)} ä¸ª Baseline æè¿°")
    print(f"âœ“ åŠ è½½äº† {len(qa_data)} ä¸ª QA æ•°æ®")
    
    # è·å–ç¬¬ä¸€ä¸ªè§†é¢‘çš„æ•°æ®
    video_id = list(baseline_desc.keys())[0]
    description = baseline_desc[video_id]['description']
    vqa_list = qa_data[video_id].get('generated_vqa', [])
    
    # æå–äº‹å®
    facts = extract_qa_sentences(vqa_list)
    print(f"\nè§†é¢‘ {video_id} çš„äº‹å®æ•°: {len(facts)}")
    
    if facts:
        print(f"ç¬¬ä¸€ä¸ªäº‹å®: {facts[0][:100]}...")


def example_2_batch_evaluation():
    """ç¤ºä¾‹ 2: æ‰¹é‡è¯„ä¼°ç‰¹å®šè§†é¢‘"""
    print("\n" + "="*80)
    print("ç¤ºä¾‹ 2: æ‰¹é‡è¯„ä¼°")
    print("="*80)
    
    from description_check.exp2_consistency_check import (
        load_baseline_descriptions,
        load_qa_data,
        extract_qa_sentences,
        check_consistency
    )
    import os
    import time
    
    # æ£€æŸ¥ API å¯†é’¥
    api_key = os.environ.get('GEMINI_API_KEY')
    if not api_key or api_key == 'your_gemini_api_key_here':
        print("âš ï¸  æœªè®¾ç½®æœ‰æ•ˆçš„ API å¯†é’¥ï¼Œè·³è¿‡ API è°ƒç”¨")
        print("   è®¾ç½®æ–¹æ³•: export GEMINI_API_KEY='your_key'")
        return
    
    # åŠ è½½æ•°æ®
    baseline_desc = load_baseline_descriptions(
        "/home/24068286g/CCD_VQA/VRU/src/description_generation/gemini_descriptions_20260119_062930.json"
    )
    qa_data = load_qa_data(
        "/home/24068286g/CCD_VQA/VRU/src/description_generation/generated_vqa_eng.json"
    )
    
    # è¯„ä¼°å‰ 3 ä¸ªè§†é¢‘
    video_ids = list(baseline_desc.keys())[:3]
    
    results = []
    for video_id in video_ids:
        desc = baseline_desc[video_id]['description']
        facts = extract_qa_sentences(qa_data[video_id].get('generated_vqa', []))
        
        scores = []
        for fact in facts[:2]:  # ä»…è¯„ä¼°å‰ 2 ä¸ªäº‹å®ä»¥èŠ‚çœæ—¶é—´
            score = check_consistency(desc, fact)
            scores.append(score)
            time.sleep(0.3)
        
        avg_score = np.mean(scores) if scores else 0
        results.append({
            'video_id': video_id,
            'average_score': avg_score,
            'fact_count': len(facts)
        })
        
        print(f"è§†é¢‘ {video_id}: å¹³å‡åˆ† = {avg_score:.3f}")
    
    return results


def example_3_custom_evaluation():
    """ç¤ºä¾‹ 3: è‡ªå®šä¹‰è¯„ä¼°æµç¨‹"""
    print("\n" + "="*80)
    print("ç¤ºä¾‹ 3: è‡ªå®šä¹‰è¯„ä¼°")
    print("="*80)
    
    # ç›´æ¥åˆ›å»ºè¯„ä¼°å‡½æ•°
    
    def custom_consistency_check(desc: str, fact: str) -> dict:
        """è‡ªå®šä¹‰çš„ä¸€è‡´æ€§æ£€æŸ¥ï¼Œè¿”å›æ›´è¯¦ç»†çš„ä¿¡æ¯"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ è‡ªå·±çš„é€»è¾‘
        # ä¾‹å¦‚ï¼šä½¿ç”¨ä¸åŒçš„ LLMã€ä¸åŒçš„ Prompt ç­‰
        
        result = {
            'description_length': len(desc),
            'fact_length': len(fact),
            'contains_fact': fact.lower() in desc.lower()
        }
        return result
    
    desc = "è¿™æ˜¯ä¸€ä¸ªå…³äºäº¤é€šäº‹æ•…çš„æè¿°..."
    fact = "è¿™æ˜¯ä¸€ä¸ªéªŒè¯äº‹å®..."
    
    result = custom_consistency_check(desc, fact)
    print(f"è‡ªå®šä¹‰æ£€æŸ¥ç»“æœ: {result}")


def example_4_result_analysis():
    """ç¤ºä¾‹ 4: åˆ†æç°æœ‰çš„è¯„ä¼°ç»“æœ"""
    print("\n" + "="*80)
    print("ç¤ºä¾‹ 4: ç»“æœåˆ†æ")
    print("="*80)
    
    from description_check import RESULTS_DIR
    
    # æŸ¥æ‰¾æœ€æ–°çš„ç»“æœæ–‡ä»¶
    result_files = list(RESULTS_DIR.glob("consistency_evaluation_*.json"))
    
    if not result_files:
        print("âŒ æœªæ‰¾åˆ°è¯„ä¼°ç»“æœæ–‡ä»¶")
        print("   è¯·å…ˆè¿è¡Œ exp2_consistency_check.py æˆ– .ipynb")
        return
    
    # åŠ è½½æœ€æ–°çš„ç»“æœ
    latest_file = sorted(result_files)[-1]
    print(f"\nğŸ“‚ åŠ è½½ç»“æœ: {latest_file}")
    
    with open(latest_file, 'r', encoding='utf-8') as f:
        results = json.load(f)
    
    # åˆ†æç»“æœ
    baseline_stats = results['baseline']['statistics']
    refined_stats = results['refined']['statistics']
    
    print(f"\nBaseline ç»Ÿè®¡:")
    print(f"  å¹³å‡åˆ†: {baseline_stats['mean']:.4f}")
    print(f"  æ ‡å‡†å·®: {baseline_stats['std']:.4f}")
    
    print(f"\nRefined ç»Ÿè®¡:")
    print(f"  å¹³å‡åˆ†: {refined_stats['mean']:.4f}")
    print(f"  æ ‡å‡†å·®: {refined_stats['std']:.4f}")
    
    print(f"\næ”¹è¿›å¹…åº¦: {results['comparison']['improvement_percent']:+.2f}%")


def example_5_visualization():
    """ç¤ºä¾‹ 5: ç”Ÿæˆè‡ªå®šä¹‰å¯è§†åŒ–"""
    print("\n" + "="*80)
    print("ç¤ºä¾‹ 5: è‡ªå®šä¹‰å¯è§†åŒ–")
    print("="*80)
    
    import matplotlib.pyplot as plt
    from description_check import RESULTS_DIR
    
    # åŠ è½½ç»“æœ
    result_files = list(RESULTS_DIR.glob("consistency_scores_*.csv"))
    
    if not result_files:
        print("âŒ æœªæ‰¾åˆ° CSV ç»“æœæ–‡ä»¶")
        return
    
    import pandas as pd
    df = pd.read_csv(sorted(result_files)[-1])
    
    print(f"âœ“ åŠ è½½äº† {len(df)} æ¡è®°å½•")
    print(f"\næ•°æ®æ‘˜è¦:")
    print(df.describe())
    
    # å¯ä»¥è¿›ä¸€æ­¥å¤„ç†æ•°æ®
    # ä¾‹å¦‚ï¼šè®¡ç®—æ”¹è¿›åˆ†æ•°
    df['improvement'] = df['refined_score'] - df['baseline_score']
    print(f"\næ”¹è¿›åˆ†æ•°ç»Ÿè®¡:")
    print(df['improvement'].describe())


def example_6_integration_workflow():
    """ç¤ºä¾‹ 6: å®Œæ•´çš„é›†æˆå·¥ä½œæµ"""
    print("\n" + "="*80)
    print("ç¤ºä¾‹ 6: å®Œæ•´å·¥ä½œæµ")
    print("="*80)
    
    print("""
    å®Œæ•´çš„é›†æˆå·¥ä½œæµåº”è¯¥åŒ…æ‹¬ï¼š
    
    1. æ•°æ®å‡†å¤‡
       - åŠ è½½ Baseline å’Œ Refined æè¿°
       - åŠ è½½ QA æ•°æ®å’ŒéªŒè¯äº‹å®
    
    2. è¯„ä¼°æ‰§è¡Œ
       - è°ƒç”¨ LLM è¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥
       - æ”¶é›†è¯„ä¼°åˆ†æ•°
    
    3. ç»“æœåˆ†æ
       - è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
       - å¯¹æ¯” Baseline vs Refined
    
    4. å¯è§†åŒ–å±•ç¤º
       - ç»˜åˆ¶ç®±çº¿å›¾å’Œå…¶ä»–ç»Ÿè®¡å›¾è¡¨
       - ç”Ÿæˆè®ºæ–‡ç”¨å›¾è¡¨
    
    5. æŠ¥å‘Šç”Ÿæˆ
       - ä¿å­˜è¯¦ç»†ç»“æœ
       - ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
       - å¯¼å‡ºè®ºæ–‡ç´ æ
    
    æ‰€æœ‰è¿™äº›éƒ½å·²åœ¨ exp2_consistency_check.py å’Œ .ipynb ä¸­å®ç°ï¼
    """)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ä¸€è‡´æ€§æ£€æŸ¥å®éªŒä½¿ç”¨ç¤ºä¾‹"
    )
    parser.add_argument(
        "example",
        nargs="?",
        type=int,
        default=4,
        help="è¦è¿è¡Œçš„ç¤ºä¾‹ (1-6, é»˜è®¤ 4)"
    )
    
    args = parser.parse_args()
    
    examples = {
        1: example_1_basic_usage,
        2: example_2_batch_evaluation,
        3: example_3_custom_evaluation,
        4: example_4_result_analysis,
        5: example_5_visualization,
        6: example_6_integration_workflow,
    }
    
    if args.example in examples:
        examples[args.example]()
    else:
        print(f"âŒ ç¤ºä¾‹ {args.example} ä¸å­˜åœ¨")
        print(f"å¯ç”¨ç¤ºä¾‹: {list(examples.keys())}")
        
        print("\nè¿è¡Œæ‰€æœ‰ç¤ºä¾‹:")
        for num, func in examples.items():
            try:
                func()
            except Exception as e:
                print(f"âš ï¸  ç¤ºä¾‹ {num} å‡ºé”™: {e}")
