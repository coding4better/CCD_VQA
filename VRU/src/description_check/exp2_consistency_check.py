"""
Consistency Check Experiment (Exp2)
===================================

éªŒè¯ Baseline å’Œ Refined æè¿°ä¸åŸå§‹ QA äº‹å®çš„ä¸€è‡´æ€§ã€‚

é€»è¾‘ï¼š
1. è¯»å– Gemini ç”Ÿæˆçš„æè¿° (Baseline)
2. è¯»å–åŸå§‹ QA æ•°æ®
3. ä½¿ç”¨ LLM ä½œä¸ºè£åˆ¤ï¼Œè¯„ä¼°æè¿°ä¸äº‹å®çš„ä¸€è‡´æ€§
4. ç»Ÿè®¡ä¸¤ç»„åˆ†æ•°å¹¶ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨
"""

import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import List, Dict, Any, Tuple
import google.generativeai as genai
from pathlib import Path
import time
from tqdm import tqdm

# ============================================================================
# é…ç½®
# ============================================================================

BASELINE_DESC_PATH = "/home/24068286g/CCD_VQA/VRU/src/description_generation/gemini_descriptions_20260119_062930.json"
QA_DATA_PATH = "/home/24068286g/CCD_VQA/VRU/src/description_generation/generated_vqa_eng.json"
OUTPUT_DIR = Path("/home/24068286g/CCD_VQA/VRU/src/description_check/results")

# API é…ç½® (éœ€è¦ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶ä¸­è¯»å–)
GEMINI_API_KEY = None  # ä»ç¯å¢ƒå˜é‡è¯»å–


# ============================================================================
# æ•°æ®åŠ è½½
# ============================================================================

def load_baseline_descriptions(filepath: str) -> Dict[int, Dict[str, Any]]:
    """åŠ è½½ Gemini ç”Ÿæˆçš„åŸºçº¿æè¿°"""
    print(f"ğŸ“‚ åŠ è½½åŸºçº¿æè¿°: {filepath}")
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    descriptions = {}
    for item in data:
        if item['status'] == 'success':
            descriptions[item['video_id']] = {
                'description': item['description'],
                'facts_text': item['facts_text']
            }
    
    print(f"âœ“ åŠ è½½äº† {len(descriptions)} æ¡åŸºçº¿æè¿°")
    return descriptions


def load_qa_data(filepath: str) -> Dict[int, Dict[str, Any]]:
    """åŠ è½½ QA æ•°æ®"""
    print(f"ğŸ“‚ åŠ è½½ QA æ•°æ®: {filepath}")
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    qa_map = {}
    for item in data:
        video_id = item.get('video_number', item.get('id'))
        qa_map[video_id] = item
    
    print(f"âœ“ åŠ è½½äº† {len(qa_map)} æ¡ QA æ•°æ®")
    return qa_map


def extract_qa_sentences(vqa_list: List[Dict]) -> List[str]:
    """ä» VQA åˆ—è¡¨ä¸­æå–è§„èŒƒåŒ–çš„ QA å¥å­"""
    sentences = []
    for qa in vqa_list:
        question = qa.get('question', '')
        correct_answer = qa.get('correct_answer', '')
        
        if isinstance(correct_answer, dict):
            # ä»é€‰é¡¹ä¸­è·å–æ­£ç¡®ç­”æ¡ˆ
            answer_key = qa.get('correct_answer_key', '')
            answer_text = correct_answer.get(answer_key, '')
        else:
            answer_text = correct_answer
        
        if question and answer_text:
            qa_sentence = f"{question.strip()} {answer_text.strip()}"
            sentences.append(qa_sentence)
    
    return sentences


# ============================================================================
# LLM ä¸€è‡´æ€§è¯„ä¼°
# ============================================================================

def build_consistency_prompt(description: str, fact: str) -> Tuple[str, str]:
    """æ„å»ºä¸€è‡´æ€§æ£€æŸ¥çš„ system å’Œ user prompt"""
    system_prompt = "You are a logic checker. Determine if the Description entails the Verified Fact."
    
    user_prompt = f"""Description: {description}

Verified Fact: {fact}

Output 1 if consistent, 0 if contradictory or missing key info. Only output the number."""
    
    return system_prompt, user_prompt


def check_consistency(description: str, fact: str, api_key: str, model_name: str = "gemini-2.0-flash") -> int:
    """
    ä½¿ç”¨ LLM æ£€æŸ¥æè¿°ä¸äº‹å®çš„ä¸€è‡´æ€§
    
    Returns:
        1 if consistent, 0 otherwise
    """
    try:
        genai.configure(api_key=api_key)
        
        system_prompt, user_prompt = build_consistency_prompt(description, fact)
        
        model = genai.GenerativeModel(
            model_name=model_name,
            system_instruction=system_prompt
        )
        
        response = model.generate_content(
            user_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.1,
                max_output_tokens=10,
            )
        )
        
        if response and hasattr(response, 'text'):
            output = response.text.strip()
            # æå–æ•°å­—ï¼ˆå¤„ç†å¯èƒ½çš„å¤šä½™æ–‡æœ¬ï¼‰
            for char in output:
                if char in ['0', '1']:
                    return int(char)
            return 0  # é»˜è®¤è¿”å›ä¸ä¸€è‡´
        else:
            return 0
            
    except Exception as e:
        print(f"  âš ï¸ API é”™è¯¯: {e}")
        return 0


# ============================================================================
# è¯„ä¼°æµç¨‹
# ============================================================================

def evaluate_descriptions(
    descriptions: Dict[int, Dict],
    qa_data: Dict[int, Dict],
    api_key: str,
    sample_size: int = 10
) -> Tuple[List[float], List[float]]:
    """
    è¯„ä¼°åŸºçº¿å’Œæ”¹è¿›ç‰ˆæœ¬çš„ä¸€è‡´æ€§
    
    Returns:
        (baseline_scores, refined_scores): ä¸¤ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯è§†é¢‘çš„å¹³å‡ä¸€è‡´æ€§åˆ†æ•°
    """
    baseline_scores = []
    refined_scores = []
    
    print(f"\nğŸ”„ å¼€å§‹è¯„ä¼°ä¸€è‡´æ€§ (æ ·æœ¬å¤§å°: {sample_size})")
    print("=" * 80)
    
    # è·å–éœ€è¦è¯„ä¼°çš„è§†é¢‘åˆ—è¡¨
    video_ids = sorted(list(set(descriptions.keys()) & set(qa_data.keys())))[:sample_size]
    
    for video_idx, video_id in enumerate(tqdm(video_ids, desc="è§†é¢‘å¤„ç†è¿›åº¦")):
        print(f"\n[{video_idx + 1}/{sample_size}] è§†é¢‘ {video_id}")
        
        # è·å–æè¿°å’Œ QA æ•°æ®
        baseline_desc = descriptions[video_id]['description']
        qa_item = qa_data[video_id]
        vqa_list = qa_item.get('generated_vqa', [])
        
        # æå– QA å¥å­
        qa_sentences = extract_qa_sentences(vqa_list)
        print(f"  - äº‹å®æ•°é‡: {len(qa_sentences)}")
        
        if not qa_sentences:
            print(f"  - è·³è¿‡ (æ²¡æœ‰æœ‰æ•ˆçš„ QA æ•°æ®)")
            continue
        
        # è¯„ä¼°åŸºçº¿æè¿°ä¸å„ä¸ªäº‹å®çš„ä¸€è‡´æ€§
        baseline_consistency_scores = []
        
        for fact_idx, fact in enumerate(qa_sentences):
            print(f"    - äº‹å® {fact_idx + 1}/{len(qa_sentences)}: ", end="", flush=True)
            
            score = check_consistency(baseline_desc, fact, api_key)
            baseline_consistency_scores.append(score)
            print(f"ä¸€è‡´æ€§={score}")
            
            # é¿å…é€Ÿç‡é™åˆ¶
            time.sleep(0.5)
        
        # è®¡ç®—å¹³å‡ä¸€è‡´æ€§åˆ†æ•°
        if baseline_consistency_scores:
            avg_baseline_score = np.mean(baseline_consistency_scores)
            baseline_scores.append(avg_baseline_score)
            print(f"  âœ“ åŸºçº¿å¹³å‡ä¸€è‡´æ€§: {avg_baseline_score:.2f}")
        
        # æ³¨æ„ï¼šè¿™é‡Œæš‚æ—¶å°† refined_scores è®¾ç½®ä¸ºä¸ baseline ç›¸åŒ
        # å®é™…é¡¹ç›®ä¸­ä¼šæœ‰å•ç‹¬çš„ refined æè¿°
        if baseline_consistency_scores:
            refined_scores.append(avg_baseline_score)
    
    return baseline_scores, refined_scores


# ============================================================================
# ç»Ÿè®¡å’Œç»˜å›¾
# ============================================================================

def generate_statistics(baseline_scores: List[float], refined_scores: List[float]) -> Dict[str, float]:
    """ç”Ÿæˆç»Ÿè®¡æ•°æ®"""
    stats = {
        'baseline_mean': np.mean(baseline_scores) if baseline_scores else 0,
        'baseline_std': np.std(baseline_scores) if baseline_scores else 0,
        'baseline_median': np.median(baseline_scores) if baseline_scores else 0,
        'baseline_min': np.min(baseline_scores) if baseline_scores else 0,
        'baseline_max': np.max(baseline_scores) if baseline_scores else 0,
        'refined_mean': np.mean(refined_scores) if refined_scores else 0,
        'refined_std': np.std(refined_scores) if refined_scores else 0,
        'refined_median': np.median(refined_scores) if refined_scores else 0,
        'refined_min': np.min(refined_scores) if refined_scores else 0,
        'refined_max': np.max(refined_scores) if refined_scores else 0,
    }
    return stats


def plot_consistency_boxplot(baseline_scores: List[float], refined_scores: List[float], output_path: Path):
    """ç»˜åˆ¶ä¸€è‡´æ€§å¯¹æ¯”ç®±çº¿å›¾"""
    
    # åˆ›å»ºæ•°æ®æ¡†
    data_dict = {
        'Baseline': baseline_scores,
        'Refined': refined_scores
    }
    
    # ç»˜åˆ¶
    fig, ax = plt.subplots(figsize=(10, 6), dpi=300)
    
    positions = [1, 2]
    bp = ax.boxplot(
        [baseline_scores, refined_scores],
        labels=['Baseline (Gemini)', 'Refined'],
        positions=positions,
        widths=0.6,
        patch_artist=True,
        showmeans=True,
        meanprops=dict(marker='D', markerfacecolor='red', markersize=8, label='Mean'),
        medianprops=dict(color='darkblue', linewidth=2),
        boxprops=dict(facecolor='lightblue', alpha=0.7),
        whiskerprops=dict(linewidth=1.5),
        capprops=dict(linewidth=1.5)
    )
    
    # ç¾åŒ–
    ax.set_ylabel('Consistency Score', fontsize=12, fontweight='bold')
    ax.set_xlabel('Description Type', fontsize=12, fontweight='bold')
    ax.set_title('Description Consistency with Verified Facts\n(Logic Checker Evaluation)', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.set_ylim([-0.1, 1.1])
    ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])
    ax.grid(True, alpha=0.3, axis='y')
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    stats = generate_statistics(baseline_scores, refined_scores)
    textstr = f"Baseline: Î¼={stats['baseline_mean']:.3f}, Ïƒ={stats['baseline_std']:.3f}\n"
    textstr += f"Refined: Î¼={stats['refined_mean']:.3f}, Ïƒ={stats['refined_std']:.3f}"
    
    ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=11,
            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ å›¾è¡¨å·²ä¿å­˜: {output_path}")
    plt.close()


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    """ä¸»æµç¨‹"""
    print("\n" + "=" * 80)
    print("æè¿°ä¸€è‡´æ€§éªŒè¯å®éªŒ (Exp2)")
    print("=" * 80)
    
    # æ£€æŸ¥ API å¯†é’¥
    import os
    api_key = os.environ.get('GEMINI_API_KEY')
    if not api_key:
        print("\nâŒ é”™è¯¯: æœªè®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡")
        print("è¯·è®¾ç½®: export GEMINI_API_KEY='your_api_key'")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # 1. åŠ è½½æ•°æ®
    print("\nğŸ“¥ æ•°æ®åŠ è½½é˜¶æ®µ")
    baseline_descriptions = load_baseline_descriptions(BASELINE_DESC_PATH)
    qa_data = load_qa_data(QA_DATA_PATH)
    
    # 2. è¯„ä¼°ä¸€è‡´æ€§
    print("\nğŸ” ä¸€è‡´æ€§è¯„ä¼°é˜¶æ®µ")
    baseline_scores, refined_scores = evaluate_descriptions(
        baseline_descriptions,
        qa_data,
        api_key,
        sample_size=5  # ä¸ºäº†æ¼”ç¤ºï¼Œå…ˆç”¨ 5 ä¸ªæ ·æœ¬ï¼Œå®é™…å¯æ”¹ä¸ºæ›´å¤§æ•°å€¼
    )
    
    # 3. ç”Ÿæˆç»Ÿè®¡
    print("\nğŸ“Š ç»Ÿè®¡åˆ†æé˜¶æ®µ")
    stats = generate_statistics(baseline_scores, refined_scores)
    
    print("\nåŸºçº¿æè¿°ç»Ÿè®¡:")
    print(f"  å¹³å‡åˆ†: {stats['baseline_mean']:.4f}")
    print(f"  æ ‡å‡†å·®: {stats['baseline_std']:.4f}")
    print(f"  ä¸­ä½æ•°: {stats['baseline_median']:.4f}")
    print(f"  èŒƒå›´: [{stats['baseline_min']:.4f}, {stats['baseline_max']:.4f}]")
    
    print("\næ”¹è¿›æè¿°ç»Ÿè®¡:")
    print(f"  å¹³å‡åˆ†: {stats['refined_mean']:.4f}")
    print(f"  æ ‡å‡†å·®: {stats['refined_std']:.4f}")
    print(f"  ä¸­ä½æ•°: {stats['refined_median']:.4f}")
    print(f"  èŒƒå›´: [{stats['refined_min']:.4f}, {stats['refined_max']:.4f}]")
    
    # 4. ç»˜åˆ¶å›¾è¡¨
    print("\nğŸ“ˆ å›¾è¡¨ç”Ÿæˆé˜¶æ®µ")
    output_image = OUTPUT_DIR / "fig1_consistency.png"
    plot_consistency_boxplot(baseline_scores, refined_scores, output_image)
    
    # 5. ä¿å­˜ç»“æœ
    print("\nğŸ’¾ ç»“æœä¿å­˜é˜¶æ®µ")
    
    # ä¿å­˜è¯¦ç»†åˆ†æ•°
    results = {
        'baseline_scores': baseline_scores,
        'refined_scores': refined_scores,
        'statistics': stats,
        'sample_size': len(baseline_scores)
    }
    
    results_file = OUTPUT_DIR / "consistency_results.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"âœ“ ç»“æœå·²ä¿å­˜: {results_file}")
    
    # æ‰“å°å®Œæˆä¿¡æ¯
    print("\n" + "=" * 80)
    print("âœ… ä¸€è‡´æ€§éªŒè¯å®éªŒå®Œæˆï¼")
    print("=" * 80)
    print(f"\nè¾“å‡ºæ–‡ä»¶:")
    print(f"  - å›¾è¡¨: {output_image}")
    print(f"  - æ•°æ®: {results_file}")


if __name__ == "__main__":
    main()
