{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4803689",
   "metadata": {},
   "source": [
    "# Google Colab - Gemini è§†é¢‘æè¿°ç”Ÿæˆå·¥ä½œæµ\n",
    "\n",
    "è¿™ä¸ª Notebook ç”¨äºåœ¨ Google Colab ä¸­ä½¿ç”¨ Gemini API ç”Ÿæˆè§†é¢‘æè¿°ã€‚\n",
    "\n",
    "**ä¼˜ç‚¹:**\n",
    "- âœ“ æ—  VPN åœ°ç†é™åˆ¶ï¼ˆäº‘ç«¯æ‰§è¡Œï¼‰\n",
    "- âœ“ å…è´¹è®¡ç®—èµ„æº\n",
    "- âœ“ Google Drive é›†æˆ\n",
    "- âœ“ è‡ªåŠ¨ä¿å­˜å’Œä¸‹è½½ç»“æœ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bb0bca",
   "metadata": {},
   "source": [
    "# Google Colab - Gemini è§†é¢‘æè¿°ç”Ÿæˆ\n",
    "\n",
    "è¿™ä¸ª Notebook ç”¨äºåœ¨ Google Colab ä¸­è¿è¡Œ Gemini APIï¼Œç”Ÿæˆè§†é¢‘æè¿°ã€‚\n",
    "\n",
    "**ä¼˜ç‚¹:**\n",
    "- âœ“ æ—  VPN åœ°ç†é™åˆ¶\n",
    "- âœ“ å…è´¹è®¡ç®—èµ„æº\n",
    "- âœ“ Google Drive é›†æˆ\n",
    "- âœ“ è‡ªåŠ¨ä¿å­˜å’Œä¸‹è½½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfa81a4",
   "metadata": {},
   "source": [
    "## Step 1: å®‰è£…ä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fdc660",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-generativeai pandas numpy -q\n",
    "print(\"âœ“ ä¾èµ–å®‰è£…å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f545c065",
   "metadata": {},
   "source": [
    "## Step 2: å¯¼å…¥åº“å’Œè®¾ç½® API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7d96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from google.colab import drive, files\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "GEMINI_API_KEY = \"your_api_key_here\"\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "print(\"âœ“ API å·²é…ç½®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a3bf6",
   "metadata": {},
   "source": [
    "## Step 3: æŒ‚è½½ Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98277421",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "csv_path = '/content/drive/MyDrive/QA_pair_v1_3options.csv'\n",
    "print(f\"âœ“ Drive å·²æŒ‚è½½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10689b5",
   "metadata": {},
   "source": [
    "## Step 4: åŠ è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f3ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qa_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        facts = []\n",
    "        for i in range(1, 7):\n",
    "            q_col = f'q{i}_text'\n",
    "            a_col = f'q{i}_ans_correct'\n",
    "            if q_col in df.columns and a_col in df.columns:\n",
    "                q_text = row.get(q_col, '')\n",
    "                q_ans = row.get(a_col, '')\n",
    "                if pd.notna(q_text) and pd.notna(q_ans):\n",
    "                    q_text = str(q_text).strip().replace('\\n', ' ')\n",
    "                    q_ans = str(q_ans).strip().replace('\\n', ' ')\n",
    "                    facts.append(f\"Fact {i}: {q_text} Answer: {q_ans}.\")\n",
    "        data.append({'video_id': str(row['video_number']), 'facts_text': '\\n'.join(facts)})\n",
    "    return data\n",
    "\n",
    "data = load_qa_data(csv_path)\n",
    "print(f\"âœ“ åŠ è½½äº† {len(data)} æ¡æ•°æ®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5679122b",
   "metadata": {},
   "source": [
    "## Step 5: ç”Ÿæˆæè¿°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_description(video_id, facts_text):\n",
    "    try:\n",
    "        prompt = f\"Based on these facts:\\n\\n{facts_text}\\n\\nGenerate a detailed description (300-400 words).\"\n",
    "        model = genai.GenerativeModel(\"models/gemini-2.0-flash-exp\")\n",
    "        response = model.generate_content(prompt)\n",
    "        if response and response.text:\n",
    "            return {'video_id': video_id, 'status': 'success', 'description': response.text}\n",
    "        else:\n",
    "            return {'video_id': video_id, 'status': 'failed', 'error': 'Empty response'}\n",
    "    except Exception as e:\n",
    "        return {'video_id': video_id, 'status': 'failed', 'error': str(e)}\n",
    "\n",
    "print(\"âœ“ å‡½æ•°å·²å®šä¹‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa36bbe0",
   "metadata": {},
   "source": [
    "## Step 6: æ‰¹é‡å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(data, num_items=10):\n",
    "    results = []\n",
    "    for i, item in enumerate(tqdm(data[:num_items])):\n",
    "        result = generate_description(item['video_id'], item['facts_text'])\n",
    "        results.append(result)\n",
    "        time.sleep(1)\n",
    "    return results\n",
    "\n",
    "results = process_batch(data, num_items=10)\n",
    "success = sum(1 for r in results if r['status'] == 'success')\n",
    "print(f\"âœ“ å®Œæˆ! æˆåŠŸ: {success}/{len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6283d3",
   "metadata": {},
   "source": [
    "## Step 7: ä¿å­˜ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45efe4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = f'results_{timestamp}.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "files.download(output_file)\n",
    "print(f\"âœ“ ç»“æœå·²ä¸‹è½½: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a157984",
   "metadata": {},
   "source": [
    "# ğŸš€ Gemini è§†é¢‘æè¿°ç”Ÿæˆ - Colab ç‰ˆæœ¬\n",
    "\n",
    "åœ¨ Google Colab è¿è¡Œï¼Œé¿å…æœ¬åœ°ç½‘ç»œé™åˆ¶\n",
    "\n",
    "## ğŸ“‹ ä½¿ç”¨æ­¥éª¤\n",
    "1. è®¾ç½® Gemini API å¯†é’¥\n",
    "2. ä¸Šä¼ æˆ–æŒ‚è½½æ•°æ®æ–‡ä»¶\n",
    "3. è¿è¡Œæ¨ç†å·¥ä½œæµ\n",
    "4. ä¸‹è½½ç»“æœ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d166157",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 1: å®‰è£…ä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„åŒ…\n",
    "!pip install google-generativeai pandas numpy -q\n",
    "print(\"âœ“ ä¾èµ–å®‰è£…å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b96880",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 2: è®¾ç½® Gemini API å¯†é’¥\n",
    "\n",
    "âš ï¸ **æ›¿æ¢ä¸ºä½ çš„å®é™…å¯†é’¥**\n",
    "- è·å–åœ°å€: https://aistudio.google.com/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a2f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# âš ï¸ åœ¨è¿™é‡Œè®¾ç½®ä½ çš„ API å¯†é’¥\n",
    "GEMINI_API_KEY = \"your_gemini_api_key_here\"  # æ›¿æ¢ä¸ºå®é™…å¯†é’¥\n",
    "\n",
    "# é…ç½® API\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# éªŒè¯å¯†é’¥\n",
    "try:\n",
    "    models = list(genai.list_models())\n",
    "    print(f\"âœ“ API å¯†é’¥æœ‰æ•ˆï¼Œå¯ç”¨æ¨¡å‹: {len(models)} ä¸ª\")\n",
    "    print(f\"  æ¨èæ¨¡å‹: gemini-2.0-flash\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ API å¯†é’¥éªŒè¯å¤±è´¥: {e}\")\n",
    "    print(\"è¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81a1a75",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 3: æ•°æ®åŠ è½½\n",
    "\n",
    "### æ–¹æ³• A: ä» Google Drive æŒ‚è½½ï¼ˆæ¨èï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a4bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "\n",
    "# æŒ‚è½½ Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# è®¾ç½® CSV æ–‡ä»¶è·¯å¾„ï¼ˆæ ¹æ®ä½ çš„å®é™…è·¯å¾„ä¿®æ”¹ï¼‰\n",
    "# å¯ä»¥å…ˆä¸Šä¼  CSV åˆ° Google Driveï¼Œç„¶åå¤åˆ¶è·¯å¾„\n",
    "csv_path = '/content/drive/MyDrive/QA_pair_v1_3options.csv'\n",
    "\n",
    "print(f\"âœ“ Google Drive å·²æŒ‚è½½\")\n",
    "print(f\"CSV è·¯å¾„: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fbe665",
   "metadata": {},
   "source": [
    "### æ–¹æ³• B: ç›´æ¥ä¸Šä¼ æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6592895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦‚æœä¸ç”¨ Driveï¼Œå¯ä»¥ç›´æ¥ä¸Šä¼ æ–‡ä»¶\n",
    "from google.colab import files\n",
    "\n",
    "# ç‚¹å‡»ä¸Šä¼ æŒ‰é’®ï¼Œé€‰æ‹© QA_pair_v1_3options.csv\n",
    "uploaded = files.upload()\n",
    "\n",
    "# è·å–ä¸Šä¼ çš„æ–‡ä»¶å\n",
    "csv_filename = list(uploaded.keys())[0]\n",
    "csv_path = f'/content/{csv_filename}'\n",
    "\n",
    "print(f\"âœ“ æ–‡ä»¶å·²ä¸Šä¼ : {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a480a8b7",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 4: å®šä¹‰æ•°æ®åŠ è½½å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec9c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def format_qa_pair(question: str, answer: str, fact_num: int) -> str:\n",
    "    \"\"\"æ ¼å¼åŒ–å•ä¸ª QA å¯¹\"\"\"\n",
    "    question = question.strip().replace('\\n', ' ')\n",
    "    answer = answer.strip().replace('\\n', ' ')\n",
    "    return f\"Fact {fact_num}: {question} Answer: {answer}.\"\n",
    "\n",
    "def extract_facts_from_row(row: pd.Series) -> str:\n",
    "    \"\"\"ä»æ•°æ®è¡Œæå–æ‰€æœ‰ QA å¯¹\"\"\"\n",
    "    facts = []\n",
    "    for i in range(1, 7):\n",
    "        q_text_col = f'q{i}_text'\n",
    "        q_ans_col = f'q{i}_ans_correct'\n",
    "        \n",
    "        if q_text_col in row and q_ans_col in row:\n",
    "            if pd.notna(row[q_text_col]) and pd.notna(row[q_ans_col]):\n",
    "                fact_text = format_qa_pair(\n",
    "                    row[q_text_col], \n",
    "                    row[q_ans_col], \n",
    "                    i\n",
    "                )\n",
    "                facts.append(fact_text)\n",
    "    \n",
    "    return '\\n'.join(facts)\n",
    "\n",
    "def load_qa_data(csv_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"åŠ è½½å¹¶å¤„ç† QA æ•°æ®\"\"\"\n",
    "    print(f\"ğŸ“ æ­£åœ¨åŠ è½½æ•°æ®: {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"âœ“ æˆåŠŸåŠ è½½ {len(df)} æ¡è®°å½•\")\n",
    "    \n",
    "    processed_data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        video_id = row['video_number']\n",
    "        facts_text = extract_facts_from_row(row)\n",
    "        \n",
    "        processed_data.append({\n",
    "            'video_id': video_id,\n",
    "            'facts_text': facts_text\n",
    "        })\n",
    "    \n",
    "    print(f\"âœ“ å¤„ç†å®Œæˆ\")\n",
    "    return processed_data\n",
    "\n",
    "# æµ‹è¯•æ•°æ®åŠ è½½\n",
    "data = load_qa_data(csv_path)\n",
    "print(f\"\\nç¤ºä¾‹æ•°æ® (Video {data[0]['video_id']}):\")\n",
    "print(data[0]['facts_text'][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5677b469",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 5: å®šä¹‰ Gemini æ¨ç†å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "def build_prompt(facts_text: str) -> str:\n",
    "    \"\"\"æ„å»ºæ¨ç† Prompt\"\"\"\n",
    "    prompt = f\"\"\"Based on the following facts about a traffic accident video:\n",
    "\n",
    "{facts_text}\n",
    "\n",
    "Please generate a detailed and coherent description of the accident scene, including:\n",
    "1. Weather and lighting conditions\n",
    "2. Traffic environment\n",
    "3. Road configuration\n",
    "4. Type of collision\n",
    "5. Primary cause\n",
    "6. Prevention measures\n",
    "\n",
    "Keep the description concise and professional (300-400 words).\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def generate_description(video_id: int, facts_text: str, model_name: str = \"gemini-2.0-flash\") -> Dict:\n",
    "    \"\"\"ä½¿ç”¨ Gemini ç”Ÿæˆæè¿°\"\"\"\n",
    "    try:\n",
    "        # æ„å»º Prompt\n",
    "        prompt = build_prompt(facts_text)\n",
    "        \n",
    "        # åˆ›å»ºæ¨¡å‹\n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        \n",
    "        # ç”Ÿæˆå†…å®¹\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                temperature=0.7,\n",
    "                max_output_tokens=512,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if response and hasattr(response, 'text'):\n",
    "            return {\n",
    "                'video_id': video_id,\n",
    "                'status': 'success',\n",
    "                'description': response.text,\n",
    "                'facts_text': facts_text,\n",
    "                'model': model_name\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'video_id': video_id,\n",
    "                'status': 'failed',\n",
    "                'error': 'Empty response'\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'video_id': video_id,\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# æµ‹è¯•å•æ¡æ¨ç†\n",
    "print(\"æµ‹è¯•æ¨ç†...\")\n",
    "test_item = data[0]\n",
    "test_result = generate_description(test_item['video_id'], test_item['facts_text'])\n",
    "\n",
    "if test_result['status'] == 'success':\n",
    "    print(f\"\\nâœ“ æ¨ç†æˆåŠŸï¼\")\n",
    "    print(f\"\\nVideo {test_result['video_id']} æè¿°:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(test_result['description'][:300] + \"...\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(f\"\\nâŒ æ¨ç†å¤±è´¥: {test_result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c300b",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 6: æ‰¹é‡å¤„ç†æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_batch(data: List[Dict], num_items: int = 10, delay: float = 1.0) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    æ‰¹é‡å¤„ç†æ•°æ®\n",
    "    \n",
    "    Args:\n",
    "        data: æ•°æ®åˆ—è¡¨\n",
    "        num_items: å¤„ç†æ•°é‡\n",
    "        delay: æ¯æ¬¡è¯·æ±‚ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰ï¼Œé¿å…è¶…è¿‡é€Ÿç‡é™åˆ¶\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"\\nå¼€å§‹æ‰¹é‡å¤„ç†ï¼ˆå…± {num_items} æ¡ï¼‰\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, item in enumerate(tqdm(data[:num_items], desc=\"å¤„ç†è¿›åº¦\")):\n",
    "        print(f\"\\n[{i+1}/{num_items}] å¤„ç† Video {item['video_id']}...\")\n",
    "        \n",
    "        result = generate_description(item['video_id'], item['facts_text'])\n",
    "        results.append(result)\n",
    "        \n",
    "        if result['status'] == 'success':\n",
    "            print(f\"  âœ“ æˆåŠŸ\")\n",
    "        else:\n",
    "            print(f\"  âŒ å¤±è´¥: {result['error']}\")\n",
    "        \n",
    "        # å»¶è¿Ÿï¼Œé¿å…é€Ÿç‡é™åˆ¶\n",
    "        if i < num_items - 1:\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    # ç»Ÿè®¡\n",
    "    success_count = sum(1 for r in results if r['status'] == 'success')\n",
    "    fail_count = sum(1 for r in results if r['status'] == 'failed')\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"å¤„ç†å®Œæˆï¼\")\n",
    "    print(f\"  æˆåŠŸ: {success_count}/{len(results)}\")\n",
    "    print(f\"  å¤±è´¥: {fail_count}/{len(results)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# è®¾ç½®å¤„ç†æ•°é‡ï¼ˆå¯ä¿®æ”¹ï¼‰\n",
    "NUM_ITEMS = 10  # å…ˆå¤„ç† 10 æ¡ï¼Œæµ‹è¯•æ•ˆæœ\n",
    "\n",
    "# å¼€å§‹æ‰¹é‡å¤„ç†\n",
    "results = process_batch(data, num_items=NUM_ITEMS, delay=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaac4f8",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 7: æŸ¥çœ‹ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e8646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ˜¾ç¤ºå‰ 2 æ¡æˆåŠŸçš„ç»“æœ\n",
    "print(\"\\næ ·æœ¬ç»“æœï¼š\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "success_results = [r for r in results if r['status'] == 'success']\n",
    "\n",
    "for i, result in enumerate(success_results[:2], 1):\n",
    "    print(f\"\\nã€ç»“æœ #{i}ã€‘\")\n",
    "    print(f\"Video ID: {result['video_id']}\")\n",
    "    print(f\"æ¨¡å‹: {result.get('model', 'N/A')}\")\n",
    "    print(f\"\\nç”Ÿæˆçš„æè¿°:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(result['description'])\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109dc368",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 8: ä¿å­˜ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc17e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# ç”Ÿæˆæ—¶é—´æˆ³\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# ä¿å­˜æ‰€æœ‰ç»“æœ\n",
    "output_file = f'/content/gemini_descriptions_{timestamp}.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ“ ç»“æœå·²ä¿å­˜: {output_file}\")\n",
    "\n",
    "# ä¿å­˜å¤±è´¥è®°å½•\n",
    "errors = [r for r in results if r['status'] == 'failed']\n",
    "if errors:\n",
    "    error_file = f'/content/errors_{timestamp}.json'\n",
    "    with open(error_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(errors, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"âœ“ é”™è¯¯è®°å½•å·²ä¿å­˜: {error_file}\")\n",
    "\n",
    "# ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š\n",
    "report = {\n",
    "    'total': len(results),\n",
    "    'success': sum(1 for r in results if r['status'] == 'success'),\n",
    "    'failed': sum(1 for r in results if r['status'] == 'failed'),\n",
    "    'timestamp': timestamp\n",
    "}\n",
    "\n",
    "report_file = f'/content/report_{timestamp}.json'\n",
    "with open(report_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {report_file}\")\n",
    "print(f\"\\nğŸ“Š å¤„ç†ç»Ÿè®¡:\")\n",
    "print(f\"  æ€»æ•°: {report['total']}\")\n",
    "print(f\"  æˆåŠŸ: {report['success']}\")\n",
    "print(f\"  å¤±è´¥: {report['failed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f040c53",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 9: ä¸‹è½½ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# ä¸‹è½½ç»“æœæ–‡ä»¶\n",
    "print(\"ä¸‹è½½æ–‡ä»¶...\")\n",
    "files.download(output_file)\n",
    "\n",
    "if errors:\n",
    "    files.download(error_file)\n",
    "\n",
    "files.download(report_file)\n",
    "\n",
    "print(\"\\nâœ“ æ–‡ä»¶å·²ä¸‹è½½åˆ°æœ¬åœ°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7055067",
   "metadata": {},
   "source": [
    "## å¯é€‰ï¼šå¤„ç†æ›´å¤šæ•°æ®\n",
    "\n",
    "å¦‚æœå‰é¢æµ‹è¯•æˆåŠŸï¼Œå¯ä»¥å¤„ç†æ›´å¤šæ•°æ®ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dce78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¤„ç†æ‰€æœ‰æ•°æ®ï¼ˆ100 æ¡ï¼‰\n",
    "# âš ï¸ æ³¨æ„ï¼šè¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå¹¶å¯èƒ½æ¶ˆè€— API é…é¢\n",
    "\n",
    "# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥è¿è¡Œ\n",
    "# all_results = process_batch(data, num_items=len(data), delay=1.5)\n",
    "\n",
    "# # ä¿å­˜\n",
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# final_output = f'/content/gemini_all_descriptions_{timestamp}.json'\n",
    "# with open(final_output, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# print(f\"âœ“ å…¨éƒ¨ç»“æœå·²ä¿å­˜: {final_output}\")\n",
    "# files.download(final_output)\n",
    "\n",
    "print(\"ğŸ’¡ å–æ¶ˆæ³¨é‡Šä¸Šé¢çš„ä»£ç æ¥å¤„ç†å…¨éƒ¨æ•°æ®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04644007",
   "metadata": {},
   "source": [
    "## ğŸ“ ä½¿ç”¨è¯´æ˜\n",
    "\n",
    "### è¿è¡Œé¡ºåº\n",
    "1. ä¾æ¬¡è¿è¡Œæ¯ä¸ªå•å…ƒæ ¼\n",
    "2. åœ¨æ­¥éª¤ 2 è®¾ç½®ä½ çš„ Gemini API å¯†é’¥\n",
    "3. åœ¨æ­¥éª¤ 3 ä¸Šä¼ æˆ–æŒ‚è½½æ•°æ®æ–‡ä»¶\n",
    "4. æ­¥éª¤ 5 ä¼šè‡ªåŠ¨æµ‹è¯•ä¸€æ¡æ•°æ®\n",
    "5. æ­¥éª¤ 6 æ‰¹é‡å¤„ç†ï¼ˆé»˜è®¤ 10 æ¡ï¼‰\n",
    "6. æ­¥éª¤ 9 ä¸‹è½½ç»“æœ\n",
    "\n",
    "### æ³¨æ„äº‹é¡¹\n",
    "- âš ï¸ ç¡®ä¿ API å¯†é’¥æœ‰æ•ˆ\n",
    "- âš ï¸ æ³¨æ„ API é…é¢é™åˆ¶\n",
    "- âš ï¸ æ‰¹é‡å¤„ç†æ—¶è®¾ç½®åˆç†çš„å»¶è¿Ÿ\n",
    "- âš ï¸ å®šæœŸä¿å­˜ç»“æœï¼Œé¿å…æ•°æ®ä¸¢å¤±\n",
    "\n",
    "### å¸¸è§é—®é¢˜\n",
    "1. **API å¯†é’¥æ— æ•ˆ**: é‡æ–°ç”Ÿæˆå¯†é’¥\n",
    "2. **é€Ÿç‡é™åˆ¶**: å¢åŠ  `delay` å‚æ•°\n",
    "3. **é…é¢è€—å°½**: ç­‰å¾…é‡ç½®æˆ–å‡çº§è´¦æˆ·\n",
    "\n",
    "### ç»“æœæ–‡ä»¶\n",
    "- `gemini_descriptions_*.json`: æ‰€æœ‰ç»“æœ\n",
    "- `errors_*.json`: å¤±è´¥è®°å½•\n",
    "- `report_*.json`: ç»Ÿè®¡æŠ¥å‘Š"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
