#!/usr/bin/env python3
"""
è§†é¢‘ç­›é€‰ä¸»ç¨‹åº - ç”Ÿæˆä¸‰ç§ç­›é€‰ç­–ç•¥çš„ç»“æœå¯¹æ¯”
å¤ç”¨ threshold_exploration_unsupervised.py çš„å‡½æ•°
"""

import os
import sys
import json
import numpy as np
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
ROOT_DIR = "/home/24068286g/UString"
sys.path.insert(0, os.path.join(ROOT_DIR, 'VRU', 'src', 'threshold_analysis'))

# å¤ç”¨å·²æœ‰çš„å‡½æ•°
from threshold_exploration_unsupervised import (
    load_annotations,
    compute_metrics_with_global_normalization
)

# é…ç½®
OUTPUT_DIR = os.path.join(ROOT_DIR, 'VRU', 'output2')
os.makedirs(OUTPUT_DIR, exist_ok=True)

COMPLEXITY_THRESHOLD = 6
DYNAMIC_CHANGE_THRESHOLD = 0.6

def main():
    print("\n" + "="*70)
    print("è§†é¢‘ç­›é€‰ - ä¸‰ç§ç­–ç•¥å¯¹æ¯”åˆ†æ")
    print("="*70)
    
    # å¤ç”¨å·²æœ‰å‡½æ•°åŠ è½½æ•°æ®
    print("\nğŸ“Š åŠ è½½è§†é¢‘æŒ‡æ ‡ï¼ˆå¤ç”¨threshold_exploration_unsupervised.pyï¼‰...")
    df = compute_metrics_with_global_normalization()
    if df is None:
        print("âœ— æ•°æ®åŠ è½½å¤±è´¥")
        return
    
    print(f"âœ“ æˆåŠŸåˆ†æ {len(df)} ä¸ªè§†é¢‘")
    
    # è®¡ç®—åŸºçº¿ç»Ÿè®¡
    baseline_stats = {
        'count': len(df),
        'avg_complexity': df['scene_complexity'].mean(),
        'avg_dynamic': df['dynamic_change'].mean()
    }
    
    # åº”ç”¨ä¸‰ç§ç­›é€‰ç­–ç•¥
    print("\nğŸ” åº”ç”¨ç­›é€‰ç­–ç•¥...")
    
    # ç­–ç•¥1: ä»… Complexity
    complexity_only = df[df['scene_complexity'] >= COMPLEXITY_THRESHOLD].to_dict('records')
    
    # ç­–ç•¥2: ä»… Dynamic
    dynamic_only = df[df['dynamic_change'] >= DYNAMIC_CHANGE_THRESHOLD].to_dict('records')
    
    # ç­–ç•¥3: åŒé‡ç­›é€‰
    combined = df[(df['scene_complexity'] >= COMPLEXITY_THRESHOLD) & 
                  (df['dynamic_change'] >= DYNAMIC_CHANGE_THRESHOLD)].to_dict('records')
    
    # ä¿å­˜ä¸‰ä¸ªåˆ—è¡¨
    print("\nğŸ’¾ ä¿å­˜ç­›é€‰ç»“æœ...")
    
    with open(os.path.join(OUTPUT_DIR, 'filtered_complexity_only.json'), 'w', encoding='utf-8') as f:
        json.dump({
            'description': f'ä»…ä½¿ç”¨ Scene Complexity â‰¥ {COMPLEXITY_THRESHOLD} ç­›é€‰',
            'threshold': COMPLEXITY_THRESHOLD,
            'total_count': len(complexity_only),
            'videos': sorted(complexity_only, key=lambda x: x['scene_complexity'], reverse=True)
        }, f, indent=2, ensure_ascii=False)
    print(f"âœ“ ç­–ç•¥1 (ä»…Complexity): {len(complexity_only)} ä¸ªè§†é¢‘")
    
    with open(os.path.join(OUTPUT_DIR, 'filtered_dynamic_only.json'), 'w', encoding='utf-8') as f:
        json.dump({
            'description': f'ä»…ä½¿ç”¨ Dynamic Change â‰¥ {DYNAMIC_CHANGE_THRESHOLD} ç­›é€‰',
            'threshold': DYNAMIC_CHANGE_THRESHOLD,
            'total_count': len(dynamic_only),
            'videos': sorted(dynamic_only, key=lambda x: x['dynamic_change'], reverse=True)
        }, f, indent=2, ensure_ascii=False)
    print(f"âœ“ ç­–ç•¥2 (ä»…Dynamic): {len(dynamic_only)} ä¸ªè§†é¢‘")
    
    with open(os.path.join(OUTPUT_DIR, 'filtered_combined.json'), 'w', encoding='utf-8') as f:
        json.dump({
            'description': f'åŒç»´åº¦ç­›é€‰ (Complexity â‰¥ {COMPLEXITY_THRESHOLD} AND Dynamic â‰¥ {DYNAMIC_CHANGE_THRESHOLD}) - æ¨è',
            'complexity_threshold': COMPLEXITY_THRESHOLD,
            'dynamic_threshold': DYNAMIC_CHANGE_THRESHOLD,
            'total_count': len(combined),
            'videos': sorted(combined, key=lambda x: (x['scene_complexity'], x['dynamic_change']), reverse=True)
        }, f, indent=2, ensure_ascii=False)
    print(f"âœ“ ç­–ç•¥3 (åŒé‡ç­›é€‰): {len(combined)} ä¸ªè§†é¢‘")
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    def calc_stats(video_list):
        if not video_list:
            return {'count': 0, 'avg_complexity': 0, 'avg_dynamic': 0}
        complexities = [v['scene_complexity'] for v in video_list]
        dynamics = [v['dynamic_change'] for v in video_list]
        return {
            'count': len(video_list),
            'retention_rate': len(video_list) / len(df) * 100,
            'avg_complexity': np.mean(complexities),
            'avg_dynamic': np.mean(dynamics),
            'complexity_improvement': (np.mean(complexities) / baseline_stats['avg_complexity'] - 1) * 100,
            'dynamic_improvement': (np.mean(dynamics) / baseline_stats['avg_dynamic'] - 1) * 100
        }
    
    comparison = {
        'total_videos': len(df),
        'baseline': baseline_stats,
        'strategies': {
            'complexity_only': {'statistics': calc_stats(complexity_only)},
            'dynamic_only': {'statistics': calc_stats(dynamic_only)},
            'combined': {'statistics': calc_stats(combined), 'recommended': True}
        }
    }
    
    with open(os.path.join(OUTPUT_DIR, 'strategy_comparison.json'), 'w', encoding='utf-8') as f:
        json.dump(comparison, f, indent=2, ensure_ascii=False)
    
    # æ‰“å°æ‘˜è¦
    print("\n" + "="*70)
    print("ç­›é€‰ç»“æœæ‘˜è¦")
    print("="*70)
    print(f"\nåŸºçº¿: {baseline_stats['count']}ä¸ªè§†é¢‘")
    print(f"  å¹³å‡Complexity: {baseline_stats['avg_complexity']:.2f}")
    print(f"  å¹³å‡Dynamic: {baseline_stats['avg_dynamic']:.4f}")
    
    for name, strategy in [('ç­–ç•¥1-ä»…Complexity', 'complexity_only'), 
                           ('ç­–ç•¥2-ä»…Dynamic', 'dynamic_only'),
                           ('ç­–ç•¥3-åŒé‡ç­›é€‰â­', 'combined')]:
        stats = comparison['strategies'][strategy]['statistics']
        print(f"\n{name}: {stats['count']}ä¸ª ({stats['retention_rate']:.1f}%)")
        print(f"  Complexity: {stats['avg_complexity']:.2f} (+{stats['complexity_improvement']:.1f}%)")
        print(f"  Dynamic: {stats['avg_dynamic']:.4f} (+{stats['dynamic_improvement']:.1f}%)")
    
    print("\n" + "="*70)
    print("âœ“ ç­›é€‰å®Œæˆï¼")
    print("="*70)


if __name__ == '__main__':
    main()
